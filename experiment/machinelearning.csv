MCQ,Choices,Correct
What is the main difference between Polynomial Regression and Linear Regression?,"a: Polynomial Regression is always non-linear, while Linear Regression is always linear. | b: Polynomial Regression is linear on the coefficients but non-linear on the input, while Linear Regression is linear on both. | c: Polynomial Regression is always linear, while Linear Regression is always non-linear. | d: There is no difference between Polynomial Regression and Linear Regression.",b
Why do we not apply Feature Scaling in Polynomial Regression?,a: Because Feature Scaling is not necessary for Polynomial Regression. | b: Because the coefficients in Polynomial Regression can adapt their scale to put everything on the same scale. | c: Because Polynomial Regression does not involve any scaling of features. | d: Because Feature Scaling is only applicable to non-linear models.,b
When should you use Support Vector Regression (SVR)?,a: When dealing with linearly distributed data. | b: When a linear model like linear regression fits the data well. | c: When dealing with non-linear problems and data that is not linearly distributed. | d: When you want to use p-values for feature selection.,c
What is the advantage of Random Forest Regression over Decision Trees?,a: Random Forests provide better interpretability than Decision Trees. | b: Random Forests can give better predictive power than Decision Trees. | c: Decision Trees are faster to train than Random Forests. | d: Decision Trees are more accurate than Random Forests.,b
How do you find the best degree in Polynomial Regression?,a: By selecting the highest degree possible to avoid underfitting. | b: By finding the lowest root-mean-square error (RMSE) for the model. | c: By using p-values for feature selection. | d: By randomly selecting a degree and testing it.,b
What is the purpose of SVR in Machine Learning?,a: To provide better interpretability of the data. | b: To handle non-linear problems and data that is not linearly distributed. | c: To reduce the number of features in a dataset. | d: To perform feature selection using p-values.,b
Why do we need to use 'sc_Y.inverse_transform' in SVR?,a: To scale the features before fitting the SVR model. | b: To transform the predicted values back to the original scale. | c: To apply feature scaling to the target variable. | d: To remove outliers from the dataset.,b
What is the Information Gain in Decision Trees?,a: It measures the disorder in a set resulting from a split. | b: It calculates by how much the Standard Deviation decreases after each split. | c: It is the same as the Entropy in Decision Trees. | d: It is the reduction of standard deviation of the predictions.,b
